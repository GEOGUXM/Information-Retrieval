http://procure.psc.gov/acquisition/psc.pdf

   U.S. DEPARTMENT OF HEALTH AND HUMAN SERVICES PROGRAM SUPPORT CENTER
   Division of Acquisition Management Evaluation Consultant Blanket
   Purchase Agreements Users Guide March , 2001 INDEX Purpose . . . . . .
   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
   . . . . . . Page 1 Services . . . . . . . . . . . . . . . . . . . . . .
   . . . . . . . . . . . . . . . . . . . . . . . . . . Page 1 Eligibility
   Criteria for BPA Calls . . . . . . . . . . . . . . . . . . . . . . . .
   . . . . . . . Page 2 Call Review and Approval Process . . . . . . . . .
   . . . . . . . . . . . . . . . . . . . Page 3 BPA Call Request
   (contents) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
   . . Page 3 Selection of a Contractor . . . . . . . . . . . . . . . . .
   . . . . . . . . . . . . . . . . . . Page 6 Call Officer
   Responsibilities . . . . . . . . . . . . . . . . . . . . . . . . . . .
   . . . . . . Page 6 Contact Information . . . . . . . . . . . . . . . .
   . . . . . . . . . . . . . . . . . . . . . . . . Page 7 Post Award
   Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
   . . . . . . . Page 7 Attachments Attachment A - List of BPA Awardees
   Attachment B - BPA Contractor Capability Statements Attachment C -
   Sample Request for BPA Call Attachment D - Sample Cost Estimate
   Worksheet PROGRAM SUPPORT CENTER Division of Acquisition Management
   Blanket Purchase Agreement for Evaluation Consultant(s) PURPOSE: The
   purpose of the Program Support Center (PSC) Blanket Purchase Agreement
   (BPA) is to have a pool of evaluation consultants with expertise in the
   major areas of evaluation and performance measurement methodology that
   program managers in Federal departments, served by the Department of
   Health and Human Services (HHS) Program Support Center (PSC) can use.
   SERVICES: Federal government agencies that conduct evaluations or
   performance measurement projects (either internally using Federal
   program staff or externally through private contractors) often need to
   obtain technical advice on evaluation methods and standards to ensure
   that evaluations performed, or performance measurement projects
   conducted, are of high quality and the results can be effectively used
   for program management and accountability. Individual or small business
   evaluation consultants can quickly and effectively provide program
   managers with technical advice on any one or all phases of an immediate
   evaluation or performance measurement project. The types of quick
   turnaround consultation often needed include: * identification of
   evaluation or performance measurement objectives, design options, and
   strategies for stakeholder involvement; * design of evaluation
   feasibility studies, or "evaluability assessments," and use of logic
   models; * design of evaluation synthesis or meta-evaluation studies; *
   development of specific evaluation designs (e.g. quantitative or
   qualitative, experimental or quasi-experimental, single or multi-site,
   single or multi-method, implementation analysis, impact analysis,
   survey design, and sampling techniques); * selection of indicators,
   including procedures for data collection, standardization or measures,
   validity and reliability tests, and data mining and retrieval; * data
   analysis strategies, statistical procedures, and other techniques for
   presentation of results; * dissemination strategies and effective uses
   of evaluation results or methods of performance data reporting; and *
   special methodological applications (e.g., cost-benefit analysis, focus
   groups, customer surveys, content analysis, time series or trend
   analyses). 1 BLANKET PURCHASE AGREEMENT HOLDERS: The contractors
   awarded BPAs are listed in Attachment A. Each of the contractors are
   qualified and authorized to work in any and all of the service areas.
   More detailed information about each contractor (i.e. corporate
   capabilities, speciality areas) is available in Attachment B, and from
   the Contracting Officer (contact information below): Program Support
   Center Division of Acquisition Management Attn: Jo-Lynn Davis Room
   5-95, Parklawn Building 5600 Fishers Lane Rockville, MD 20857 Phone
   301-443-7076, Fax 301-443-2761 E-mail JDAVIS2@PSC.GOV Customers who
   have additional questions concerning the contractors' corporate
   capabilities, or who are considering the use of these BPAs should
   contact the Contracting Officer for additional information. Customers
   are advised not to contact or to initiate discussions about possible
   work with any of the contractors. ELIGIBILITY CRITERIA FOR BPA CALLS:
   In order to use the BPAs, the proposed work must meet the following
   criteria: * The scope of work must fit one of the areas of expertise
   described in the purpose/services section above. All required approvals
   and clearances must be obtained by the agency submitting the request,
   and those approvals must be included as part of the Request for Call
   package. * The performance for any given call must begin within the
   period of performance for the BPA. * Each Call must be fully funded at
   the time of award. * The total of the Call, excluding the PSC fee of
   2.5%*, may not exceed $100,000. The maximum total dollar amount for
   each BPA (for the one year period of performance) is $200,000. * BPA
   Calls are considered to be a modification to an existing contract.
   Therefore, the fee for a BPA Call may be found under the "modification"
   category in the PSC Fee Schedule. You may request this schedule from
   the Contracting Officer. 2 performance) is $200,000. BLANKET PURCHASE
   AGREEMENT CALL REQUEST: The Division of Acquisition Management, Program
   Support Center is responsible for the management and oversight of the
   BPAs. All requests for Calls will be reviewed by the BPA Project
   Officer and the Contracting Officer to determine if the project meets
   the eligibility criteria. The Program (or requesting) Office must
   submit a Request for Call package. The Request for Call package must
   include the following: 1. Request for Call The information required in
   order for a contractor to accurately identify the needs of the Program
   Office. This information should be in the form of a clear, complete,
   and concise statement of the purpose of the project. The Statement of
   Work should elaborate to provide a detailed description of the tasks to
   be performed by the Contractor, the necessary deliverables, and a
   delivery schedule. (See Attachment C for a Request for Call sample
   format and sample statement of work.) We will then prepare a
   solicitation package which will be sent to the Contractors. To assist
   in this process we ask that you submit this document on a 3 Â½ inch
   computer diskette, or to e-mail the information to the Contracting
   Officer at JDAVIS2@PSC.GOV. Independent Government Cost Estimate: This
   is an estimate of costs for the work identified in the Statement of
   Work. In your estimate you should consider estimated labor costs, other
   direct costs, indirect costs (fringe benefits, overhead, general and
   administrative (G&A) costs), and fee. A computational worksheet for
   estimating these costs is provided as Attachment D. The Calls issued
   under the Blanket Purchase Agreements will be awarded on a labor hour
   or a fixed-price basis. A determination of the type of contract
   mechanism to be used shall be made by the Contracting Officer in
   conjunction with the appropriate program personnel. 2. Funding Document
   An approved funding document must be provided to indicate funds
   availability. If your agency is part of the U.S. Department of Health
   and Human Services and is regularly serviced by PSC's Financial
   Management Branch, a completed Purchase/Service/Stock Requisition, Form
   HHS 393, must be provided. This is the 3 in the boxes labeled:
   Requested by, Approved by, and Funds Available. If you are unsure of
   whether or not your agency may use a HHS 393 for funds availability,
   please contact the Contracting Officer. (Note: the Food and Drug
   Administration, National Institutes of health, Centers for Disease for
   Disease Control Prevention, Health Care Finance Administration, and
   Indian Health Service regional offices may not use a HHS 393.) For
   those agencies outside the U.S. Department of Health and Human Services
   or not regularly serviced by PSC's Financial Management Branch, and
   Agency Reimbursable Work Agreement (commonly referred to as an
   Interagency Agreement), will need to be completed in order to provide
   the necessary transfer of funds. The Program Support Center has
   developed an interagency agreement form to facilitate the transfer of
   funds, PSC-45 Agency Reimbursable Work Agreement, that may be used by
   any agency. NOTE: Agencies that are required to use their own standard
   form for the interagency transfer of funds may do so, however, the form
   MUST clearly delineate the total amount of funds available for the
   project with a separate line item detailing the estimated amount of PSC
   administrative fee. 3. Sample Format for BPA Call Proposal Submission
   and Evaluation Criteria To facilitate the evaluation of each BPA Call,
   we will have prospective Contractors submit, as part of each proposal,
   separate sections entitled "Technical Proposal" and "Business
   Proposal." Information about each section is provided below: I.
   Technical Proposal You may impose a page limit for the technical
   proposal. Usually this section should not exceed 5 single-spaced pages
   and the resume of the principal evaluation consultant(s) should not
   exceed 10 single-spaced pages for each consultant. It is easier, when
   conducting the evaluation if you require that all pages must be
   numbered. Unless noted differently, three (3) copies of each proposal
   will be required for each Call. Contractors should be reminded that
   failure to comply with any aspect of technical proposal instructions
   may result in the proposal being considered nonresponsive. Evaluation
   Criteria You, as the Call Monitor, will determine the evaluation
   criteria and associated weights for each individual request for Call.
   The evaluation of the technical proposal must be conducted in
   accordance with the valid technical evaluation criteria you set forth
   in your request for Call. Therefore, you must determine evaluation
   criteria that are tailored to your specific need(s). The Call Monitor
   should select evaluation criteria which identify and correspond with
   the purpose of the requirement. When deciding the evaluation criteria
   keep in mind the attributes and properties that will determine how well
   the prospective Contractor can accomplish the work. The Government's
   technical proposal evaluation will 4 produce a numerical score (points)
   on each criterion, and when totaled, and overall score for each
   Offeror. Proposals shall be evaluated to determine the Offeror's
   ability to complete all technical requirements for performance of your
   BPA Call. Therefore, your goal is to be able to use the scoring to
   accurately determine which Contractor is offering the greatest value
   for your particular task. Generally these criteria are concerned with
   the Offeror's capability (the manner in which they propose to
   accomplish the work; and the characteristics of the firm that is to
   perform the work). The BPAs were awarded competitively, and all
   Offerors were determined to be technically acceptable to perform
   evaluations. However, any proposal for a specific Call that addresses
   only part of your technical requirement(s), or fails to address your
   specific criteria may be deemed technically unacceptable. Here are some
   examples of Evaluation Criteria. You will need to assign a point value
   for each, (usually these total to 100 points), regardless of the number
   of criteria you have. A. Technical Approach ( Points) This criteria
   focuses on the Contractor's plan to accomplish the tasks - which could
   be demonstrated through a work breakdown structure, or schedule. B.
   Knowledge of the Program or Policy ( Points) This criteria focuses on
   the context that concerns the evaluation or performance measurement
   consultation and its various tasks. C. Personnel Qualifications and
   Experience ( Points) The BPA Call requires the provision of specialized
   evaluation consultation in the following evaluation or performance
   measurement methodologies: (list the evaluation methods pertinent to
   the consultation) and prior knowledge of the following program or
   policy area(s) (list the substantive programs or policy areas relevant
   to the consultation). The Contractor shall summarize his/her training
   and consultative experience with different kinds of evaluation or
   performance measurement methods and substantive program or policy areas
   listed above. D. Consultation Management and Staffing Plan ( Points)
   The Contractor shall present a general plan for organizing and managing
   tasks included in the BPA Call, including additional clerical or
   technical staff needed to assist the principal consultant in completing
   the tasks. The plan shall indicate how consultative roles and
   responsibilities will be organized, decisions made, work monitored, and
   quality and timeliness assured. The Contractor shall attach a standard
   resume for the principal evaluation consultant(s) who will perform
   consultative services under this BPA Call. Resumes must include: the 5
   individual's full name, academic background, evaluation or performance
   measurement expertise, consultative work history, and when appropriate,
   a list of publications. Each resume shall not exceed 10 pages. II.
   Business Proposal The Contractor shall submit their business proposal
   according to your requirements. This can be at an hourly rate or daily
   billing rate. The Contractor will be required to submit documentation
   substantiating the rate. If the hourly or daily rate is a previously
   established commercial or Government rate, the Contractor may submit
   copies of prior invoices paid to facilitate assessment of
   reasonableness. Although the expectation is that the Contractor shall
   perform most of the work assigned, he/she may also submit rates for
   clerical and technical staff that they may use to assist them in
   completing assigned work. Cost proposals must be evaluated to assess
   the realism of the proposed cost/price and to determine the cost and
   value to the Government. Contractors were advised in the original BPA
   document that the technical capability would be paramount to price. If
   price is more important for your requirement you will need to advise
   Offerors of that fact. However, in either case, to be selected for
   award the business proposal must be fairly and reasonably priced. Note:
   For BPA Calls that include tasks where evaluation consultants are
   involved in the development or preparation of a Government procurement
   will incorporate the following paragraph: Contractors should be aware
   that the BPA Call contains tasks that involve the development of a
   Government procurement. Under these circumstances, the Contractor is
   obliged to not discuss the general nature or details of the Government
   procurement with any other Government entity, organization, or business
   firm without the permission of the BPA Call Monitor. SELECTION OF A
   CONTRACTOR: Each request for Call will be competed among all of the BPA
   Contractors. Requests for proposals will be sent out electronically and
   Contractors can respond electronically. The Contractors will be given a
   deadline to respond. Contractors do not have to respond to all Request
   for Proposals. Therefore, it is likely that between 1 and 5 will
   normally respond to any Call. CALL OFFICER RESPONSIBILITIES: The BPA
   Call Officer's responsibilities are generally the same as those of a
   Project Officer in any Federal agency. Initially this involves
   formulation of the request for Call, development of the evaluation
   criteria, and assurance of funding for the project. After proposals are
   received it is necessary to evaluate and score each proposal. It is not
   necessary to convene a panel, but the Call Officer must submit a review
   report documenting the strengths 6 and weaknesses of each proposal.
   After award the BPA Call Monitor must ensure that deliverables are
   being met, and funding is available for the entire duration of the
   project. For the Evaluation Consultant BPAs there is an additional
   level of assistance provided by the BPA Project Officer, who can advise
   on technical issues. If you need more information about the role and
   responsibilities of a Project Officer you can reference the Department
   of Health and Human Service's contracting guide, entitled "The
   Negotiated Contracting Process - A Guide for Project Officers."
   CONTACTS FOR THE BPAs: For more information on PSC's Evaluation
   Consultants Blanket Purchase Agreements, please contact Jo-Lynn Davis,
   Contracting Officer, at (301) 443-7076, via e-mail at JDAVIS2@PSC.GOV
   or at the following address: Program Support Center Division of
   Acquisition Management/AOS Parklawn Building, Room 5-101 5600 Fishers
   Lane Rockville, MD 20857 Project Officer: Paul Johnson (202) 401-8277
   Office of the Assistant Secretary for Planning and Evaluation Office of
   the Secretary (HHS) POST AWARD INFORMATION: A copy of the BPA Call
   award will be forwarded to you. In order to increase responsiveness to
   you, the customer, and the Contractor who is performing your
   evaluation, please adhere to the following procedures: 1. You are
   responsible for monitoring the amount of money expended and the amount
   of money remaining on your BPA Call. Any requests for increase or
   decrease of funds, or for modification of the work to be performed must
   be submitted to the Contracting Officer. Modifications requiring an
   increase of funds must be accompanied by an authorized funding
   document. 2. Invoices will be sent directly to the Call Officer. The
   Call Officer is responsible for reviewing the invoice. The invoice
   should, at a minimum, include the BPA number, Call number, the
   contractors name and Tax ID number. After your review, if the invoice
   is correct, you must sign the invoice. You can simply write "Approved
   for Payment/Call Officer" and sign below this statement. You must also
   sign and date a receiving report, and forward both documents to the
   finance office (see Block 21 of the Call). 7 Please note: It is
   imperative that you forward receiving reports and invoices to the
   finance office within five days to avoid paying interest penalties. If
   you would prefer to have invoices forwarded to you from the contracting
   office, and have the contracting office forward the signed invoice and
   receiving to the finance office that can be arranged. 8 Attachment A
   List of BPA Awardees Acumen, LLC Fitzgerald Consulting Attn: R. Mark
   Gritz Dr. Nicholas B. Fitzgerald 1415 Rollins Road, Suite 206 2644 N.
   Roosevelt Street Burlingame, CA 94010 Arlington, VA 22207 Assoc. For
   the Study and Health Systems Mgmt. Consultation Development of
   Community Attn: Holly Korda, Ph.D. Attn: David Chavis 5500 Friendship
   Blvd. #1126N 312 S. Frederick Ave. Chevy Chase, MD 20815 Gaithersburg,
   MD 20877 James Bell Associates Berkeley Policy Associates Attn: Elyse
   Kaye Attn: Stephen Walsh 2111 Wilson Blvd. Suite 1120 440 Grand Ave.,
   Suite 500 Arlington, VA 22201 Oakland, CA 94610-5085 Klemm Analysis
   Group Capital Research Corp. Attn: Edward Johnson Attn: John Trutko
   1785 Massachusetts Ave., NW 1910 N. Stafford Street Suite 501
   Arlington, VA 22207 Washington, DC 20036 CODA Scott Consulting Attn:
   Kristine Powell Attn: Sheryl Scott 1100 Wayne Ave., Suite 750 204
   Hammond Street Silver Spring, MD 20910 Durham, NC 27704 E.H. Pechan &
   Associates, Inc. Mary Ann Scheirer Attn: Michael Cohen Evaluation &
   Performance 5528-B Hempstead Way Measurement Consultant Springfield, VA
   22151 4616 Hillbrook Drive Annandale, VA 22003 Economic Systems, Inc.
   Attn: Anita Andrews GHK International 5514 Alma Lane, Suite 400 Attn:
   Dr. Andy Rowe Springfield, VA 22151 2702 Stratford Road Columbia, SC
   29204 EMT Associates Joel Phillips The Measurement Group, LLC 771 Oak
   Avenue Parkway, Ste. 2 Attn: Lisa Melchior, Ph. D. Folsom, CA
   95630-6802 5811a Uplander Way Culver City, CA 90230 Engineering Mgmt.&
   Economics, Inc. Attn: Bruce Block 51 Monroe St., Plaza 2 West
   Rockville, MD 20850 Attachment B CAPABILITY STATEMENTS * Association
   for the Study and Development of Community * Berkeley Policy Associates
   * CODA, Inc. * Economic Systems, Inc. * E.H. Pechan & Associates, Inc.
   * EME, Inc. * EMT Associates, Inc. * Fitzgerald Consulting * GHK
   International, Inc. * Holly Korda, Ph.D. * James Bell Associates * Mary
   Ann Scheirer, Ph.D. * Scott Consulting * The Measurement Group, LLC
   ASSOCIATION FOR THE STUDY AND DEVELOPMENT OF COMMUNITY 312 South
   Frederick, Gaithersburg, Maryland 20877 phone: 301-519-0722 $
   fax:301-519-0724 $ www.capablecommunity.com PSC Blanket Purchase
   Agreement for Evaluation Consultants I. Mission The Association for the
   Study and Development of Community (ASDC) is committed to building the
   capacity of organizations and institutions to develop the health,
   economic equity, and social justice of communities. We work to advance
   the research, practice, and knowledge of community development,
   community building, comprehensive community prevention, and
   collaboration through an integrated approach to providing research and
   evaluation support, technical assistance, and training. ASCD has the
   capacity to: * Design and organize the evaluation of complex
   multi-level interventions; * Engage diversity through culturally
   appropriate evaluation; * Foster collaboration among diverse
   stakeholders to plan, implement and use evaluation; * Enhance the
   evaluation capacity of individuals, institutions, and communities
   through training and technical assistance; * Augment the utility of
   evaluation by using research and evaluation as a conduit for
   information and a catalyst for learning. II. Key Personnel and
   Methodological Expertise Evaluation and Performance David Paul
   Margruetta Theresa Johanna Measurement Expertise Chavis Florin Hall
   Singleton Birckmayer Ph.D Ph.D Ph.D Ph.D Ph.D. Understanding and
   expertise in evaluation principles and methods in the following areas:
   !"Comprehensive community initiatives # # # # # # # # # # # # # # # # #
   # # # !"Community-based health promotion # # # # # # # # # # # # # # #
   # !"Systems change initiatives # # # # # # # # # # # # # # # #
   !"Coalition building # # # # # # # # # # # # # # # # !"Economic
   development # # # # # # # # # # # # !"Workforce development # # # #
   !"Housing assistance # # # # !"Juvenile delinquency # # # # # # # # # #
   # # prevention !"Violence prevention/treatment # # # # # # # # # # # #
   # # # # !"Youth development # # # # # # # # # # # # !"Adolescent
   pregnancy # # # # prevention !"Early childhood development # # # # # #
   # # !"Substance abuse prevention # # # # # # # # # # # # # # # #
   !"Healthcare and outcome # # # # # # # # # # # # # # # # disparities
   !"Health and social issues # # # # # # # # # # # # # # # # # # # #
   specific to minority and disadvantaged communities !"Organ donor policy
   # # # # III. Prior Experience in Evaluation or Performance Measurement
   Consultation Client Organization Year Description of Consultation
   Completed Office of Juvenile Justice 2000  Evaluating effectiveness
   OJJDP Safe Start program to and Delinquency ongoing reduce exposure to
   violence among children ages 0-6 Prevention (OJJDP) and providing
   evaluation capacity building support to 9 sites. National Crime
   Prevention 2000- Conducting evaluation of NCPC's state demonstration
   Council (NCPC) ongoing project to embed violence prevention efforts in
   state policy in 6 states. C. S. Mott Foundation and 1998- Providing
   evaluation and capacity building support to Ford Foundation ongoing the
   Community Foundation Intergroup Relations Program-a joint effort
   between the Mott and Ford Foundations and six community foundations.
   Center for Substance 2000 Designed and implemented evaluation of
   U.S.-Mexico Abuse Prevention (CSAP) Border States Initiative as
   collaborative effort between four states and a federal agency. Ewing
   Marion Kauffman 2000 Evaluated the Kansas City's Promise Initiative on
   Foundation youth and their communities. Community IMPACT! 2000
   Evaluated IMPACT!'s work and role in community building. National
   Cancer Institute 1999 Facilitated and managed design of evaluation of
   American Stop Smoking Intervention Study (ASSIST) program. Milton S.
   Eisenhower 1999 Evaluated Police Mentoring and Youth Development
   Foundation Initiative, a collaborative project between police, housing
   authority and youth organization in 5 cities. Local Initiatives Support
   1997 Evaluated national grassroots initiative in 12 cities to
   Collaborative (LISC) address social, economic, and community
   development efforts. Berkeley Policy Associates 100% employee-owned
   Berkeley Policy Associates (BPA) is an independent, employee-owned,
   woman-owned firm dedicated to providing information to facilitate
   decision-making in public policy. Our mission: BPA is dedicated to
   providing the highest quality research and consulting services to those
   who develop and implement public policy that increases social and
   economic opportunity. For over 25 years BPA research and technical
   assistance have helped make publicly-funded programs more responsive to
   clients and more accountable to sponsors, and our researchers have
   cultivated a national reputation for excellence in evaluation,
   planning, and technical assistance for public programs. BPA projects
   are staffed by teams representing diverse perspectives and academic
   disciplines, including individuals with first-hand experience operating
   programs as well as extensive analytic expertise. Research staff have
   either master's or doctoral degrees in a range of fields including
   public policy, planning, sociology, public health, economics, and
   anthropology. BPA has a national reputation for high quality work in
   conducting program evaluation and public policy research in a wide
   range of substantive areas, including: Employment and Training. Since
   the inception of the Job Training Partnership Act (JTPA) in 1983, BPA
   has led national evaluations of a broad range of employment and
   training programs. These include examinations of programs funded under
   Title II (disadvantaged youth and adults), Title III (dislocated
   workers), and Title IV (migrant and seasonal farmworkers). Welfare
   Reform. Many of the welfare reform programs being proposed by states in
   response to the Personal Responsibility and Work Opportunity
   Reconciliation Act of 1996 are aimed at employment and self-sufficiency
   for welfare clients. BPA is conducting numerous evaluations of newly
   implemented welfare programs at the state and county levels, as well as
   evaluations of services for welfare clients provided by private
   industry and non-profit agencies. Youth Education and Development.
   BPA's experience includes randomized evaluations of promising
   alternatives for youth training and development-the Center for
   Employment and Training and the Quantum Opportunities Program, as well
   as evaluation of the effectiveness of integrating technology in
   education. Services for People with Disabilities. BPA has studied a
   wide range of services targeting full participation in society by
   persons with disabilities, including public and private vocational
   rehabilitation services, independent living centers, supported
   employment, services for early intervention, personal assistance
   services, deinstitutionalization, services for: at-risk infants and
   toddlers, women with disabilities, farmworkers with disabilities, and
   people with developmental disabilities. Economic Development. BPA's
   knowledge of the needs of small businesses builds on studies of
   microenterprise development programs, short-time compensation programs,
   information use among small businesses, defense conversion, the needs
   of redevelopment zones for employment and training services, local
   support networks among minority business owners, and workplace literacy
   programs. Health and Mental Health Services. BPA has examined the
   cost-effectiveness and programmatic effectiveness of long-term care
   services and health maintenance services for elderly persons,
   coordinated systems of care for persons with psychiatric disabilities,
   and the accessibility of health insurance for persons with
   disabilities. Services for Children, Youth, and Families. BPA's
   commitment to making programs more responsive to the needs of families
   has included conducting child care needs assessments for localities,
   studying child abuse prevention services, Head Start services for
   homeless children, employer-supported child care, and needs of families
   with disabled parents. BPA has expertise in the full range of research
   and evaluation methods, including: Impact Evaluation. BPA is one of the
   few small businesses conducting policy research with expertise in
   random assignment. BPA's expertise in conducting impact evaluations
   ranges from programs for out-of-school youth to programs demonstrating
   the effectiveness of social/health maintenance organizations for the
   frail elderly. Process Evaluation. Process studies are a special area
   of expertise for BPA, including a wide range of social service programs
   from job training programs to supported employment for workers with
   disabilities. Our process studies focus on both replication and on the
   use of information to improve program operations. Quantitative
   Analysis. BPA has considerable expertise in collecting and managing
   large data sets, as well as the ability to download governmental
   databases for quantitative analysis. Needs Assessment. BPA has
   conducted needs assessments at the national, state, and local levels,
   including large-scale surveys, focus groups, case file reviews, and
   secondary data analysis. Survey Research. BPA has conducted surveys of
   numerous hard-to-survey populations, such as individuals with
   disabilities, migrant and seasonal farmworkers, and small business
   owners. We conduct computer-assisted telephone surveys, as well as mail
   and in-person surveys. We also gather information using record reviews,
   focus groups, and Delphi methods. Benefit-Cost and Cost-Effectiveness
   Analysis. BPA conducts cost-benefit and cost-analysis studies of a
   variety of programs ranging from the federal and state levels to local
   service programs. Technical Assistance. BPA's technical assistance
   efforts have included workshops on innovative fundraising methods,
   technical training to improve access for people with disabilities,
   individual consultations on program design and strategic planning, and
   organizational development. PSC Blanket Purchase Agreement for
   Evaluation Consultants CODA, Inc. I. Mission/Goals/Objectives CODA is a
   research organization with strong capabilities in social and biomedical
   science and biostatistics, offering services in surveys, epidemiologic
   research and evaluation. CODA offers a full range of survey research
   services. We are experienced in all aspects of survey design, including
   questionnaire development. We conduct mail surveys, in-person surveys
   and telephone surveys. We have survey experience on many research
   topics, using a wide variety of survey respondent populations,
   including physicians, museum visitors, caretakers of the elderly and
   disabled, participants in a parenting support program, military
   personnel, cancer patients, and teachers. We have experience in
   designing data management systems, programming survey instruments for
   computer-assisted interviewing (CATI), conducting data entry and
   cleaning and data analysis. CODA has conducted outcome evaluations and
   process evaluations, as well as needs assessments. For 5 years, we
   served as the Evaluation Support Services contractor to the Office of
   Cancer Communications, the National Cancer Institute. In addition, we
   have conducted evaluation studies for FDA, the Center for Assessment
   and Policy Development, the U.S. Marine Corps, HUD, the Smithsonian
   Institutions and the United Hospital Fund of New York. II. Key
   Personnel and Evaluation Methods/Performance Measurement Expertise J.
   Termaat D. Northrup K. Powell R. Cook C. Brown Survey design and
   operations X X X X Design of program X X X X evaluations Development of
   performance X X X measures Applied research methods X X X X X
   Statistics X X X III. Past Experience in Evaluation or Performance
   Measurement Consultation Client Organization Year Completed Description
   of Consultation Center for Devices and Radiological ongoing Evaluate
   the Feasibility and Health (CDRH), Office of Surveillance Effectiveness
   of a Sentinel and Biometrics of the Food and Drug Reporting System for
   Adverse Administration, Event Reporting of Medical Device Use in User
   Facilities, including the development of performance measures for the
   system Office of Cancer Communications, 1997 Evaluation of user
   satisfaction for National Cancer Institute callers to the Cancer
   Information Service (CIS) hotline (1-800- 4CANCER) Office of Cancer
   Communications, 1997 Evaluate overall effectiveness of National Cancer
   Institute the Cancer Information Service (CIS) Outreach Program, which
   operates through the 19 CIS regional offices Office of Cancer
   Communications, 1999 Baseline survey to evaluate National Cancer
   Institute impact of Cancer Clinical Trial Promotion Campaign to
   increase awareness of clinical trials as a potential treatment option
   for cancer patients Center for Assessment and Policy 1997 Evaluation of
   a network of Development (CAPD). community-based Family Support Centers
   in Maryland Institutional Studies Office, Smithsonian 1995 Evaluation
   of the experience of Institutions visitors to the Natural History
   Museum and the Sackler Museum United Hospital Fund of New York 1999
   Evaluation of the Hospital Palliative Care Initiative (HPCI) School of
   Public Affairs, Princeton 1998 Impact Evaluation of HUD's University
   "Moving to Opportunity" Program Human Technology, Inc. 1996
   Effectiveness of the U.S. Marine Corps' Transition Assistance
   Management Program (TAMP) 2 PSC Blanket Purchase Agreement for
   Evaluation Consultants Economic Systems, Inc. (ESI) I.
   Mission/Goals/Objectives ESI is a management-consulting firm located in
   Springfield, VA near Washington, DC. It meets the small business
   qualification based on annual revenues less than $5 million. Founded in
   1990, ESI has served a variety of clients including Federal agencies,
   Fortune 500 firms, and nonprofit associations. ESI was founded to
   provide a responsive source of high quality, objective studies and
   analyses without institutional and individual biases. We are prepared
   to support Federal evaluation programs across a broad range of program
   areas and evaluation settings. Our promise is to provide customers with
   expert, unbiased, and timely assistance in any or all facets of
   evaluation design, execution, and assessment. ESI specializes in
   supporting Federal decisionmaking and planning in a variety of policy,
   program, and management areas by way of its capacity to design and
   conduct powerful and accurate evaluations and performance measurement
   studies. To ensure top quality service, ESI consultants adhere to
   principles of scientific rigor in designing and applying methodologies
   for capturing and analyzing information. II. Key Personnel and
   Evaluation Methods/Performance Measurement Expertise The ESI consultant
   staff is an interdisciplinary team of economists, operations
   researchers, statisticians, and computer scientists. Our highly
   talented and versatile group has rich experience and diversified
   backgrounds coming from industry, Government, and the academic
   community. Key Personnel Evaluation Methods, George James Kim
   Performance Measurement Kettner, Cunningham, Ali Karthik Barnette,
   Expertise Ph.D. Ph.D. Sayer Nagaiyan Ph.D. Causal path/logic modeling X
   X X X X Meta-analysis X X X Analytical hierarchy process X X X X X
   Workflow simulation X X X Econometric modeling & analysis X X X X
   Design and maintenance of X X X X X performance measurement systems
   Cost-benefit/cost-effectiveness X X X X X analysis Survey design and
   analysis X X X X X Benchmarking X X X X X Data envelopment analysis X X
   X X X 1 III. Past Experience in Evaluation or Performance Measurement
   Consultation (selected engagements) Client Year Organization Completed
   Description of Consultation Veterans Health Current Evaluating outcomes
   and impacts of alternative models for Administration reengineering
   third party revenue collection operations in (VHA) VA hospitals.
   Entails structured interviews of stakeholders, survey data collection,
   process modeling, benchmarking, and statistical analysis. Veterans
   Current Conducting a survey-based program evaluation of five VA
   Benefits (complete programs for veterans and their surviving
   dependents. Administration 3/01) Collecting, managing, and analyzing
   data from stakeholder (VBA) interviews, large panel studies, DoD & VA
   administrative files, commercial insurance data, non-VA program
   benefits, VA customer satisfaction surveys, and extensive research
   literature on disability, needs, poverty, etc. Veterans Health 1999
   Evaluated methodology used for estimating and forecasting
   Administration potential revenues from insurance carriers for medical
   care (VHA) provided to certain veterans. Research included site visits,
   interviews of key staff and stakeholders, assessment of model's
   underlying assumptions and data sources, and statistical analysis. U.S.
   Bureau of 1999 Evaluated competing capital investment projects in terms
   Engraving and of several critical perspectives including financial
   costs Printing and benefits, risk, and alignment with the
   organization's strategic goals, business functions, and existing
   infrastructure. Assessment was based on Analytic Hierarchy Process as
   adapted in ESI-developed software. Department of 1997 Developed an
   agency-wide process and methodology for Veterans Affairs evaluating
   competing capital spending proposals so that (VA) they are consistent
   with VA's Strategic Plan and actively promote VA's goals and
   objectives. Methodology is based on Analytical Hierarchy Process (AHP)
   modeling, cost- benefit principles, assessment of best practices, and
   application of OMB guidelines. Charles Schwab 1997-1999 Developed and
   applied, advanced analytical software Co., Citicorp (ESI's Crosspoint
   Evaluator) for evaluating effectiveness Savings, CVS, and efficiency of
   systems and networks of operating units JC Penney, IRS (e.g.,
   branches). Crosspoint Evaluator is a performance measurement approach
   that incorporates Data Envelopment Analysis (DEA). 2 PSC BLANKET
   PURCHASE AGREEMENT FOR EVALUATION CONSULTANTS (January 2001) E.H.
   PECHAN & ASSOCIATES, INC. I. Mission/Goals/Objectives Founded in 1981,
   E. H. Pechan & Associates, Inc. (Pechan) specializes in management
   consulting and environmental analysis services for Federal, state and
   other government agencies. Pechan's corporate headquarters is in
   Springfield, VA; the firm also has offices in Bethesda, MD; Durham, NC;
   and Sacramento, CA. Pechan has approximately 40 staff members. Pechan's
   Management Consulting Division provides a broad range of services to
   assist clients in improving the structure, management processes and
   human resources required for effective program and organizational
   performance. Services provided include: program evaluation, performance
   measurement, management reviews, process improvement, benchmarking,
   organizational analysis, strategic planning, facilitation, surveys, and
   human resources planning. The Division's staff of senior management
   analysts includes several individuals with more than 20 years'
   experience in evaluation and other management consulting disciplines,
   who have served as officers of major consulting firms. II Key Personnel
   Michael E. Cohen is the lead Evaluation Consultant for Pechan. Mr.
   Cohen holds a Master's degree in Business Administration, is a
   Certified Management Consultant (CMC), and has over 25 years'
   experience in providing evaluation, performance measurement, and other
   management consulting experience to DHHS and other Federal Government
   agencies. His functional expertise includes program evaluation,
   performance measurement, management reviews, process improvement,
   organizational design, facilitation, benchmarking, cost-benefit
   analysis, and training/procedures development. He has experience in a
   wide range of evaluation methods, including evaluability assessments,
   and descriptive, process, and outcome evaluations. He has served
   several DHHS offices, including HRSA, NIH (NCI, NHLBI, and NICHD),
   HCFA, FDA, CDC, and SAMHSA. Mr. Cohen is also an expert in project
   planning and management. Prior to joining Pechan 13 years ago, Mr.
   Cohen was a vice president of four management consulting firms,
   including Booz, Allen & Hamilton, Macro International, and MAXIMUS. Mr.
   Cohen's skills are complemented by Pechan staff with specialized
   expertise in statistical analysis and survey research. III Past
   Experience in Evaluation and Performance Measurement Representative
   projects Mr. Cohen has directed and performed are presented below. 1.
   HRSA- Mr. Cohen directed a project to develop performance measures and
   standards for evaluating organ procurement agencies. This involved the
   development of approximately 50 candidate measures, both qualitative
   and quantitative- outcome measures, process measures, and
   organizational characteristics. This included an on-site benchmarking
   survey of organ procurement organizations to enhance understanding of
   mission, goals, organizational characteristics, and evaluation methods;
   the drafting of candidate measures and standards; and the facilitation
   of a 2-day consensus conference of experts to review and select
   appropriate measures and standards. The results of the project were
   used to assess program performance, evaluate grant proposals, develop
   performance benchmarks and best practices, identify technical
   assistance needs, and establish program regulations. 2. HRSA- Mr. Cohen
   directed an evaluation of the foreign medical education of U.S.
   citizens who have trained abroad and transferred to U.S. medical
   schools. This included an analysis of secondary data submitted by
   grantee medical schools on curricula, teaching methods, student
   characteristics, and student performance as measured by Medical Board
   test scores and other criteria. The secondary data included both
   quantitative and qualitative data, including views expressed by
   transfer students and grantee medical schools on the strengths and
   weaknesses of foreign medical curricula and teaching methods. 3.
   NIH/NICHD- Mr. Cohen provided facilitation and consultation for several
   meetings of an NIH/EPA/CDC Task Force, as well as two larger meetings
   of government and non-government experts in epidemiology, child health
   and development, environmental protection, and other disciplines, to
   plan a long-term, longitudinal evaluation of the impact of
   environmental factors on children's health. Mr. Cohen prepared summary
   reports of the two larger meetings to support the planning and design
   of the study. He also assisted in developing meeting agendas and
   discussion topics, selecting and providing guidance to other
   facilitators, and developing project plans. 4. HRSA- Mr. Cohen directed
   a nationwide mail survey and evaluation of family medicine education
   programs in medical schools. The purpose was to determine the influence
   of medical school characteristics and other variables on the
   institutionalization of family medicine programs in the schools. The
   dependent variable- institutionalization- was measured by numerical
   variables such as the faculty retention rate and the percentage of
   medical students selecting family medicine residencies, and
   nominal/attribute variables, such as the extent of collaboration of
   family medicine with other departments. The independent variables
   included quantitative measures such as the funding and age of the
   program, and qualitative measures such as the attitude and support of
   the Dean of Medicine and other clinical departments toward the program.
   5. EPA- Mr. Cohen served as Project Director for the development of a
   Management Accountability Program for EPA's Office of Research and
   Development. This included the development of procedures, interview and
   file review guides, and self-assessment checklists for conducting
   management and program reviews of organizational performance in 15
   major management processes in the areas of general management (e.g.,
   human resources), extramural management (e.g., contract
   administration), and financial management (e.g., funds control). 6.
   FDA- Evaluations of the FDA Consumer Deputy Program and the Poison
   Control Program 7. EPA- Benchmarking survey of the peer review
   processes at NIH and NASA. 8. Dept. of Education- Descriptive and
   process evaluation of the Educational Research Library. PSC Blanket
   Purchase Agreement for Evaluation Consultants EME, Inc. I.
   Mission/Goals/Objectives EME, Inc. is a healthcare consulting firm
   specializing in the planning, evaluation and implementation of
   preventive services in both health care and public health settings. The
   firm offers a 3-part program for organizations seeking training and
   assistance in defining and using performance measures. Specialties
   include multidisciplinary policy and program analysis, troubleshooting
   of problems in the implementation of programs, and the design of
   innovative software solutions to address planning, policy development
   and program evaluation issues. EME team members have worked with AHRQ,
   CDC, HCFA, HRSA, NIH and SAMHSA, as well as programs funded by those
   agencies, and with public health agencies at State and local levels,
   health care providers, and health care insurers. II. Key Personnel and
   Evaluation Methods/Performance Measurement Expertise Evaluation
   Methods, Performance Key Personnel Measurement Expertise itz in k te
   kow er Rask itzkin N Bloc Polster ersh Fish Mercan H Computer-Based
   Simulation for Evaluation ! ! ! ! Cost effectiveness analysis ! ! ! !
   Economic & Financial Analysis ! ! ! Performance Measurement Training !
   ! ! Policy Analysis ! ! ! Process and Outcome Measure Design ! ! ! ! !
   ! ! Rasch Analysis for Performance Measurement ! Stakeholder Analysis !
   Statistical /Econometric Analysis ! ! ! ! ! Surveillance System Design
   & Implementation ! ! Survey Design And Administration ! ! ! ! ! ! III.
   Past Experience in Evaluation or Performance Measurement Consultation
   Client Organization Year Description of Consultation Completed AHCPR
   1998 Analyzed lessons of experience in research on medical treatment
   effectiveness. AHRQ 2000 Demonstrated Rasch / fundamental measurement
   principles on quality of care data CDC 2000 Designed prototype GIS
   system to track efficacy Client Organization Year Description of
   Consultation Completed and efficiency of preventive cardiovascular
   disease programming CDC 1999 Developed simulation model for evaluation
   of diabetes preventive programming CDC Division of Health 2000
   Evaluated the types of health services research Sciences NCHS questions
   that can be addressed by CDC surveys El Paso County (Colorado) 2000
   Assessed program evaluation and accountability Health Department
   systems, agency-wide and developed recommendations for improvement.
   Hansen's Disease Center, 1993 Conducted needs assessment which resulted
   in Carville, LA additional $1.4 million for the 1993 Budget and $3
   million for 1994. HHS Assistant Secretary for 1999 Served on an expert
   panel that reviewed and Program Evaluation selected commendable
   evaluation projects in DHHS HRSA Maternal and Child 2000
   Designed/administered evaluation interview Health Bureau instrument to
   assess performance of grants management system HRSA Office of Planning,
   1999 Prepared several years of abstracts of ongoing Evaluation and
   Legislation and completed evaluation projects supported by HRSA HRSA
   Office of Rural Health 1999 Developed dynamic evaluation model for
   Policy assessing new Hospital Flex Program Louisiana State University
   1996 Assessed quality of telemedical services and Health Sciences
   Center implemented management information system for continuous
   evaluation of efficiency of telemedical systems. Louisiana State Prison
   1993 Assessed current correctional health systems and System interface
   with state hospital system, implemented new procedures and projected
   future needs. Louisiana State University 2001 Designed process and
   outcome measures (LSU) Health Sciences Center for disease management
   projects throughout Health Care Services Division statewide public
   hospital system LSU School of Medicine 2001 Conducted multi-faceted
   Rasch analysis of Medical Clerkship Evaluations (removing rater
   harshness/leniency effects from measures) Naval Medical Quality 1997
   Developed Baldridge-style assessment Institute questionsquestionnaire
   Social Security 2000 Developed functional assessment methodology
   Administration for the Disability Claims Process Redesign PSC Blanket
   Purchase Agreement for Evaluation Consultants EMT Associates, Inc. I.
   Mission/Goals/Objectives Mission: Produce and advocate science-based
   knowledge to improve social policy and resolve social problems. EMT is
   a dynamic firm meeting the research and training needs of public,
   private, and nonprofit organizations nationwide. Established in
   Sacramento in 1981, EMT has over 19 years of experience working with
   clients in the health and human services, education, and criminal
   justice fields. To date, the firm has completed more than 190 projects
   for local, state, and federal agencies, as well as not-for-profit and
   private organizations. Throughout its corporate history EMT has been
   dedicated to the provision of quality consulting services and products
   at a reasonable cost. EMT consistently delivers top quality products
   within the projected timeline and budget. II. Key Personnel and
   Evaluation Methods/Performance Measurement Expertise C. Feuer, Ph.D. D.
   Gilin, M.A. E. Harris, Ph.D. E. Sale, Ph.D. F. Lawrence, Ph.D. J.
   Phillips, B.A. J.F. Springer, Ph.D. K. Scott, B.S. M. Nistler, M.P.P.A.
   R. Espiritu, Ph.D. R. Kasim, Ph.D S. Hahn-Smith, Ph.D. V. Stuart B.A.
   Research and Policy Analysis/Assessment Lit review/synthesis T T T T T
   T T T Legislative monitoring T Identifying effective practices T T T T
   T T T Convening expert panels T T T T Policy briefs T T T T T Knowledge
   dissemination T T T T T Policy & program development T T T T T T
   Research and Eval Design/Data Collection/Analysis Study design/methods
   T T T T T T T T T T T T T Instrument development T T T T T T T T T T T
   Protocol development T T T T T T T T Training data collectors T T T T T
   T T T T T T Field observation T T T T T T T T T T T Conducting site
   visits T T T T T T T T T T T Survey Admin T T T T T T T T T T Database
   management T T T T T T T T Qualitative/Qualitative data analysis T T T
   T T T T T T T T T T Tech report writing T T T T T T T T T T T T T
   Performance Measurement Design of logic models T T T T T T T T T T
   Selection of quantifiable indicators T T T T T T T T T T T T Design
   data collection system T T T T T T T T T T T Monitoring performance
   trends T T T T T T T T T Program Assessment Site visits/key informant
   interviews T T T T T T T T T T T Identifying "best practices" T T T T T
   T T T Assessing cost effectiveness T T T T T T Measuring program
   outcomes T T T T T T T T T Additional Activities and Project Support
   Conference planning and support T T T T T T Technical assistance and
   training T T T T T T T T III. Recent Consultations and Projects Project
   Name Client Period CSAP National Cross-Site Eval of High Risk Youth
   (CSAP), (SAMHSA) 1996-2000 Programs Starting Early, Starting Smart Data
   Coordinating Center (CSAP), (SAMHSA) Casey Family Foundation 1997-2001
   Parenting Adolescents Cross-Site National Data (CSAP), (SAMHSA)
   1998-2001 Coordinating Center Children of Substance Abusing Parents
   National (CSAP), (SAMHSA) 1998-2001 Coordinating Center Project Youth
   Connect DCC (CSAP), (SAMHSA) 1998-2001 Friday Night Live Mentoring Eval
   California FNL Partnership 1999-2001 21st CLC After School Program
   Evaluation Sacramento City Unified School District 1999-2000 PASSage
   After School Program Eval Sacramento City Unified School District
   1999-2000 Orange County Needs Assessment Orange County Health Care
   Agency 1996-1998 Youth Power Demonstration Program Evaluation "Just Say
   No" International, Incporated 1995-1998 Pasadena Tobacco Control
   Program City of Pasadena Public Health Program 1998-1998 Family
   Advocate Project Evaluation Lake Tahoe Unified School District
   1997-1997 California Department of Alcohol and Drug Project DESTINY
   1993-1996 Programs (CDADP) Placer County Greater Collaborative
   Evaluation Placer Cty Child Abuse Prevention Council 1995-1996 Sierra
   Nevada Rural Health Coalition Evaluation El Dorado County Dept of
   Public Health 1995-1998 Tahoe Prevention Network Evaluation Tahoe
   Prevention Network (TPN) 1991-1996 Sacramento 21 Community Partnership
   Sacramento 21 Community Partnership 1991-1995 Mendocino County
   CommunityWORKs Mendocino County Department of Alcohol 1991-1996 Bering
   Strait Coalition for Prevention Nome Community Center 1996-1998 Yolo
   Youth Development Network Yolo County Department of Alcohol 1996-1998
   St. Louis Community Partnership St. Louis County Youth Programs
   1991-1996 Corporation for a Healthy Community Corporation for a Health
   Community 1996-1996 Cal Partners Statewide Coalition Community Services
   Planning Council 1995-1998 Head Start Family Services Center Evaluation
   North Coast Opportunities, Inc. 1993-1995 Blue Bay Healing Center
   Native American Project CSAP, SAMHSA 1988-1995 Youth Development Policy
   Series California Ctr for Health Improvement (CCHI) 1998 Economic Costs
   of Substance Abuse in San Diego County County of San Diego Health
   Services Agency 1997 SB 1741: Youth Pilot Program Evaluation Foundation
   Consortium 1997-2002 Welfare Reform and Substance Abuse Treatment Needs
   in Santa Clara Valley Health and Hospital Foundation 1997 California
   Consortium Quality of Life Indicators Foundation Consortium 1998
   Community Risk and Need Profiles for California Counties University of
   California, San Francisco 2000-2001 Safe Schools and Violence
   Prevention Office California Office of Education School/Law Enforcement
   Partnership School 1997-1999 Safety/Violence Prevention Training
   Career-Oriented Mentoring Technical Assistance and CDAPD 2000-2003
   Training Youth Mentoring Technical Assistance and Training CDADP
   2000-2003 Program Community Alcohol and Drug Prevention Technical CDAPD
   2000-2003 Assistance and Training Program F I T Z G E R A L D C O N S U
   L T I N G I. Statement of Mission and Goals Dr. Nicholas B. Fitzgerald
   is the sole proprietor of Fitzgerald Consulting, founded in 1998 to
   provide evaluation and measurement services to public and private
   sector clients concerned with documenting and understanding the
   performance of human service programs. It is our contention that
   performance measurement in federal program evaluation stands to improve
   the most by devoting greater resources to evaluation design and data
   analysis. We therefore view the involvement of an evaluator in the
   design phase as crucial to identifying appropriate evaluation and
   measurement objectives through stakeholder involvement in evaluability
   assessment and logic modeling activities. The selection and development
   of appropriate performance indicators, data collection systems, and
   analysis plans is a necessary outgrowth and extension of these initial
   design activities. At the other end, we see our strengths in data
   analysis and special methodological applications. In particular, we can
   offer the Government expertise in multivariate analysis for testing
   program theories and for establishing relationships among program
   linkages specified in logic models. Among the analytic skills we offer
   that would be relevant to such tasks are multiple regression analysis
   in its various forms and its extension to path analysis and structural
   equation modeling. II. Key Personnel and Description of Methodological
   Strengths Dr. Nicholas Fitzgerald has over 20 years of experience in
   program evaluation, including the provision of technical assistance in
   evaluation. He received his Ph.D. in Research Methodology from Indiana
   University (1983) where he specialized in Evaluation. Dr. Lawrence
   Hotchkiss is a statistical consultant with a Ph.D. in Sociology from
   the University of Wisconsin (1976). Dr. Hotchkiss specializes in
   quantitative methods and computer applications and has over 30 years
   experience with advanced statistical applications. The table below
   summarizes our expertise in evaluation and performance measurement.
   Substantive Areas of Consultation Expertise Fitzgerald Hotchkiss
   Identification of Evaluation/Measurement Objectives & Options X X
   Stakeholder Involvement, Evaluability Assessment & Logic Modeling X
   Design of Evaluation Syntheses and Meta-Evaluations/Analyses X
   Development of Specific Evaluation/Statistical Designs X X
   Selection/Development of Indicators & Data Collection Procedures X X
   Data Analysis, Statistical Procedures, & Presentation Techniques X X
   Special Methodological Applications (e.g., Cost Benefit & Time Series)
   X Process Areas of Consultation Expertise Fitzgerald Hotchkiss
   Preparation of Project Proposals and Statements of Work X X Preparation
   of OMB Clearance/Justification Statements X X Review of Project Work
   Plans X X Participation on External Technical Advisory Panels X Review
   of Draft and Final Reports/Products X X Serve as Technical Advisor to
   Project Officer X X 2 6 4 4 N . R O O S E V E L T S T R E E T * A R L I
   N G T O N V A * 2 2 2 0 7 P H O N E : 7 0 3 . 5 3 6 . 3 9 3 8 * E M A I
   L : N I C K F I T Z 2 @ A O L . C O M  2  March 2, 2001 Fitzgerald
   Consulting III. Corporate Experience in Evaluation Consultation Client
   Year Description of Consultation Organization Completed Bard College
   2001 External evaluator on a study (begun in 1998) of undergraduate
   science education initiatives to help disadvantaged students succeed in
   and pursue careers in science. Evaluation methods include on-site
   visits, interviews (telephone and in-person), surveys, and longitudinal
   analysis of student records data. ROW Sciences 2000 Developed
   evaluation plan for CSAT/HHS to use in assessing the implementation,
   outcomes, and cost- effectiveness of the San Diego County (CA) Family
   Drug Treatment Court Program. AARP 2000 Designed a merged database to
   statistically analyze survey data collected by the client; analyzed the
   data using logistic regression; wrote and presented final report to the
   client. GWU 1999 Designed and carried out the quantitative analyses of
   data collected by the client to measure the implementation and outcomes
   of the DCPS' Summer STARS Program. Wrote most of the final evaluation
   report. Also performed as senior analyst on a GWU/Westat field research
   study of effective practices in Migrant Education for USED (OME/OPE).
   Designed the sampling, data collection, and data analysis plans,
   carried out site visits, wrote case study reports; contributed to the
   final report. CCSSO/IMEC 1999 Managed the implementation of a national
   survey developed by the client to measure accountability and
   coordination issues in compensatory education. Provided technical
   assistance to the States in helping respondents complete the data
   collection. Provided data quality control and database design
   assistance to the client; conducted data analyses; presented
   preliminary and final results to the study advisory committee;
   collaborated with the advisory committee to present the final results
   at a conference and in developing the final written report for
   dissemination. SRI International 1998 Reviewed and revised OMB Forms
   Clearance packages NSF 1998 Reviewed OMB Forms Clearance packages to
   ensure that technically adequate data collection and analysis plans
   were prepared by contractors; conducted a quick turn-around evaluation
   of NSF dissemination policy issues using survey research; edited
   contractor reports for technical soundness and readability prior to
   dissemination. 2 6 4 4 N . R O O S E V E L T S T R E E T * A R L I N G
   T O N V A * 2 2 2 0 7 P H O N E : 7 0 3 . 5 3 6 . 3 9 3 8 * E M A I L :
   N I C K F I T Z 2 @ A O L . C O M GHK INTERNATIONAL INC. GHK
   International was established in 1973. It is an employee-owned firm
   with permanent offices in the U.S., England, Canada and Hong Kong.
   Long-term project offices are located in 22 countries in South East
   Asia and Europe. GHK has a substantial evaluation and performance
   management practice that operates principally from our U.S. and English
   offices. The Blanket Purchase Agreement includes the following staff
   and associates from GHK: Andy Rowe, Joe Wholey, Jake Barkdoll, John
   McLaughlin, Howard Greenwald, Gwen Power and Jan Probst. (The initials
   of these consultants are used in the tables below). Our vision To be
   recognised as setting the standard of excellence in all that we do. Our
   Mission GHK provides expert advice and technical assistance that
   enables clients to achieve their objectives in the most efficient and
   effective manner. GHK: * enhances clients' capacity to manage change *
   promotes socially responsible investment * takes account of stakeholder
   interests * bases its work on best practices, research and innovative
   thinking. Our core values Profitability, professionalism, collegiality,
   learning, social responsibility. Key personnel and Evaluation Methods /
   Performance Measurement Expertise AR JW JB JMc HG GP JP Evaluation
   Methods Interviewing [ [ [ [ [ [ [ Focus groups
