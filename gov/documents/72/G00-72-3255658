http://www.cstl.nist.gov/FY2000TAR/09_cbdata.pdf

   2.9 Chemical and Biochemical Data Data acquisition, manipulation and
   handling are mandates for NIST activities. Thus, CSTL activities in the
   area of chemical and biochemical data are numerous and broad. These
   activities can be subdivided beyond chemical or biochemical activities,
   into areas of experimental data and derived data, which are CSTL
   addresses the needs obtained from modeling of data handling in
   processes or statistical analysis industry by focusing on of other
   data. Some of the data the areas of highest impact across those
   included in the databases are industries. Tackling these rigorously
   measured and problems requires both evaluated, and thus can be NIST's
   expertise in data called NIST Standard Reference Databases (SRD). Other
   handling as well as the databases, due to the nature and source of
   their data, are less extensive chemical and rigorously evaluated, and
   therefore not termed a reference biochemical expertise of database.
   Both classes of NIST databases have comparable CSTL brought to bear on
   utility and significance, because they contain the most accurate them.
   data in the country, if not the world. The NIST WebBook - NIST Chemical
   Reference Data for Industry W.G. Mallard, P.J. Linstrom, P.J. Christian
   (838), and J.F. Liebman (University of Maryland, Baltimore County) The
   major goal of the WebBook (http://WebBook.nist.gov/) is to During FY00
   the sixth supply data from NIST critical evaluations, though the
   WebBook edition of the NIST is also a broad resource of chemical data
   from many sources. In Chemistry WebBook was parallel with the efforts
   to gather and evaluate data, another major released providing data for
   part of this project is aimed at providing the mechanisms needed more
   than 35,900 to make these and other NIST chemical reference data
   available compounds and between on the Internet. These efforts are part
   of NIST's program on 8000 and 17000 users per Systems Integration for
   Manufacturing Applications (SIMA). There week. is a substantial amount
   of organic thermochemical data (heats of formation, entropies, heat
   capacities, heats of reaction) as well as thermophysical property data
   (vapor pressure, viscosity, boiling point, melting point, etc.) that
   have not appeared in widely available compilations and, hence, they are
   largely unknown to the technical community. One part of this project is
   to find, organize, and evaluate those data. In addition, there is a
   need to make ancillary thermochemical data, such as phase-change
   enthalpies, available. Data on infrared (IR), ultraviolet (UV) and mass
   spectra, and other analytical techniques are also important resources
   that are often difficult to find. The NIST Mass Spectral Database:
   Extending the Evaluation S.E. Stein, A. Mikaya, J. Klassen, D.
   Tchekhovskoi, C.L. Clifton, W.G. Mallard (838), and D. Zhu (Guest
   Researcher) The determination of the identity of a compound is a
   central problem in chemistry. For volatile substances, the most widely
   used, sensitive, and definitive "fingerprint" for making such
   identifications is the electron-ionization mass spectrum. In practice,
   identifications begin with automated mass spectral Ïlibrary searchingÓ
   against a comprehensive library of reference spectra. The reliability
   of such identifications depends directly on both the quality of the
   reference library and the algorithms for matching mass spectra. Three
   parallel 79 activities are involved in this program: addition of new
   data; quality control; and algorithm development. Addition of New Data:
   High quality mass spectra are acquired to both fill gaps in coverage
   and confirm the accuracy of spectra for important compounds. Related
   information such as retention indices and chemical identification
   information are also sought. Quality Control: Expert evaluators use a
   variety of Over the past year, software tools along with a traditional
   evaluation has been structure-spectrum analysis to confirm completed
   for nearly all the accuracy of spectra. Starting with spectra received
   since the the 1998 version of the library, all previous release.
   129,136 distributed spectra for 107,886 compounds have been subject to
   evaluation. Algorithm Development: This includes the optimization and
   testing of automated computer methods for both identifying compounds
   from their mass spectra and for finding possible defects in library
   spectra. Automated Gas Chromatography/Mass Spectral Decomposition and
   Analysis: Tools for Automating and Improving the Use of GC/MS
   Instruments S.E. Stein, J.J. Reed, J. Klassen , W.G. Mallard (838), and
   O. Toropov (Guest Researcher) This program has been supported by the
   Defense Threat Reduction Agency (DTRA) to provide a method for
   determining whether chemical weapons banned under the Chemical Weapons
   Convention are present in samples analyzed by GC/MS. The software
   implementing the algorithms must function without the need for the
   operator to examine the data. This ensures that any proprietary
   information that may be contained in the underlying data of treaty
   participants is protected. Moreover, the conventional method involving
   the manual analysis of GC/MS data files can be time consuming, operator
   dependent and error prone. So, in this project, GC/MS data is examined
   and a detailed noise analysis is performed, followed by a deconvolution
   of each of the chromatographic peaks in the GC/MS analysis. The
   extracted component spectra are then compared to reference spectra
   using a series of algorithms that reflect the degree of confidence that
   the reference and reference spectra originated from the same compound.
   The process of extracting the individual components in a complex data
   file proceeds in a series of four steps: noise analysis, component
   perception, signal extraction, and compound identification. Ongoing
   testing involves a number of laboratories both in the United States and
   abroad where specific chemical agent samples are examined. Quantitative
   Infrared Database Developed to Support Remote Sensing Applications P.M.
   Chu, F.R. Guenther, G.C. Rhoderick, and P.A. Johnson (839) Details
   provided in the Environmental Measurements section. Central Analytical
   Database of the Organization for the Prohibition of Chemical Weapons
   (OPCW) G. W. Mallard (838), E. White V (839), and E. S. Etz (837)
   Details provided in the International Measurement Standards section.
   Measurements, Modeling and Database Development for Supercritical
   Fluids and Alternative Solvents T.J. Bruno and A.F. Lagalante (838)
   Details provided in the Physical Property Data section. 80
   Computational Chemistry Comparison and Benchmark Database R.D. Johnson
   III (838) As computer power increases there is more reliance on
   modeling and computational chemistry in the chemical industry, due to
   the increased safety, speed, and the low cost of computational
   modeling, as compared to laboratory measurements. Ab initio
   computational chemistry methods can provide accurate values for
   structures, entropies, and heats of formation. However, the calculation
   time, and therefore cost, increases greatly as the accuracy sought
   increases. The errors in the computational methods are systematic and
   dependent on the methods used and functional groups that compose the
   molecule. In order to take The results of over 32000 advantage of
   computational methods, accuracy and cost need to calculations are
   available on the web, including be evaluated. A set of benchmark
   molecules and reactions with data from over 600 reliable thermochemical
   and spectral data, including evaluated species with well-known values
   and uncertainties, were selected. The measured data also enthalpies of
   formation, included gas-phase enthalpies of formation, entropies,
   vibrational and calculations frequencies, and structures. Data are
   currently being generated employing 20 methods from ab initio
   calculations for comparison with the experimental and 10 basis sets.
   data. The calculations cover eighteen ab initio methods and more than
   fifteen basis sets. Chemical Kinetics Database on the Web T.C. Allison,
   J.A. Manion, R.D. Levin, R.E. Huie (838), and C.Y. Lin (Guest
   Researcher) A web-based interface to the NIST Chemical Kinetics
   Database has been developed and is available at
   http://kinetics.nist.gov/. The interface is implemented in HTML to
   ensure portability. More sophisticated features make use of common web
   languages such as CGI, JavaScript, and Java, which are readily
   available via most browsers. The database and supporting code have been
   completely rewritten, permitting development of a number of
   enhancements. In addition to the previous features, such as links
   between bibliographic and kinetic data and a rate constant plotting
   function, a number of enhancements have been made, including the
   ability to query on several fields using logical operators. A new
   data-entry system was developed to allow the database to be updated by
   a number CSTL has made many of people working simultaneously on either
   data entry or quality advances to the Chemical Kinetics Database
   control. Updates to the database will occur much more frequently
   including more frequent than in the past and errors can be corrected
   very rapidly. updates and rapid error Hypertext links direct the user
   to the page in the NIST WebBook correction. containing information on
   the selected compound. A "thermodynamics calculator" was developed to
   read information on chemical structure and energetics from the output
   of several popular quantum chemistry codes and compute thermodynamic
   quantities from this information. Enhancements to the searching
   capabilities of the database include the recognition of chemical names
   and formulas associated with compounds in the database. 81 Targeted
   Evaluations of Kinetic and Thermodynamic Data J.A. Manion, T.C.
   Allison, J.W. Hudgens, D.R. Burgess, W. Tsang, R.E. Huie, R.D. Levin,
   A. Fahr (838), and C.Y. Lin (Guest Researcher) The development of
   models can have tremendous economic and environmental impact by
   permitting the rapid exploration of methods to improve yields of
   products and avoid unwanted or toxic byproducts. These tools are often
   not being utilized, primarily due to the absence of reliable, evaluated
   kinetic and thermodynamic data and the inability to extrapolate from
   available data. Production, disposal, and environmental fates of
   chlorinated hydrocarbons are extremely important, since they are
   utilized in many industries and products, including plastics,
   pharmaceuticals, computers, pesticides, and medical devices. Many of
   the processes involving chlorinated hydrocarbons are amenable to
   modeling if the necessary data are available; thus, chlorinated
   hydrocarbons were targeted for study. The available experimental
   thermodynamic data of chlorinated compounds were found to be internally
   inconsistent and the methodologies for predicting their enthalpies of
   formation, badly flawed. Currently, the evaluated heats of Development
   of methods to extend these data to larger formation of over 70 chlorine
   systems is ongoing. Also under development are commercially important
   tools that take the molecular property output from, e.g., chlorinated
   species have been GAUSSIAN calculations, and immediately calculate
   evaluated and posted, along JANAF-like thermodynamic tables as well as
   place the with their molecular and information in formats useful to
   common modeling thermodynamic properties derived from quantum packages.
   Parallel to these efforts was the implementation mechanics
   calculations. In of reviews of experimental data on the kinetics of key
   addition, the kinetics of reaction classes important in chlorination
   systems. In the approximately 100 reactions course of these reviews,
   various problem areas were have been reviewed and identified. These
   were resolved using both computational evaluated. and experimental
   approaches and have extended our fundamental understanding of these
   reactions. Transfer of Thermodynamics Research Center (TRC) from Texas
   A&M University to NIST M. Frenkel, Q. Dong, X. Yan, X. Hong, W.M.
   Haynes (838), K.R. Hall (Texas A&M), and R.F. Kayser (TS) Details
   provided in the Physical Property Data section. Standard Property
   Surfaces for Key Industrial Fluids E.W. Lemmon, M.O. McLinden, D.G.
   Friend, A.H. Harvey, M.L. Huber (838), A.P. Peskin (ITL), R.T Jacobsen
   (Idaho National Engineering and Environmental Laboratory), S.G.
   Penoncello (U. of Idaho), R. Span (Ruhr University, Germany), and K.
   Knobloch (University of Zittau, Germany) Details provided in the
   Physical Property Data section. Thermodynamic Data for Aqueous
   Terrestrial Processes at Subfreezing Temperatures D.G. Archer and R.W.
   Carter (838) Details provided in the Physical Property Data section.
   Thermophysical Properties of Water and Aqueous Mixtures A.H. Harvey,
   D.G. Friend, L.A. Watts, J.M.H. Levelt Sengers, J.S. Gallagher (838),
   and K. Knobloch (University of Zittau, Germany) Details provided in the
   Physical Property Data section. 82 Fundamental Properties of Trace
   Components of Fuel Gas T.J. Bruno, A.F. Lagalante, G.M. Bachmeyer
   (838), and K.I. Henning (Institute Louis Pasteur, France) Natural gas
   and liquefied petroleum gas (LPG) consist primarily of The United
   States methane or petroleum, respectively, but between 300 and 400
   consumes approximately additional compounds may be present at varying
   levels, with most 22 trillion cubic feet of fuel of these naturally
   occurring and others intentionally added during gas each year, with
   fuel processing. Most fuel gas is used industrially and for electric
   gas being defined broadly power generation, whereas only 20 % is used
   residentially. as natural gas and Efficient and safe design of plant
   equipment operated with fuel liquefied petroleum gas. gases depends
   upon sufficient knowledge of the properties of the individual
   components of natural gas and LPG. Moreover, components present at low
   or trace levels can have a significant impact on the overall properties
   of the fuel gas mixture. Our most recent work with fuel gas has
   included (1) development of chromatographic databases for trace
   compound identification, (2) measurement of odorant diffusion in
   natural gas, and (3) measurement of the hydrolysis reaction of carbonyl
   sulfide (COS) in propane. The chromatographic databases permit trace
   components to be identified on the basis of retention indices. These
   databases are used in performing ASTM methods requiring the
   determination of gas composition. Work on the diffusion of sulfur
   odorants in natural gas resulted from the problem of odorant fading. We
   determined that the actual diffusion was significantly lower than what
   is predicted by theory, an observation that has caused the industry to
   evaluate odorization procedures. In LPG, we measured the kinetics of
   COS hydrolysis, and discovered that the hydrolysis only occurs in a
   separate aqueous phase, not in water dissolved in LPG, impacting how
   LPG producers test for COS. Moreover, we have developed a separation
   method to remove COS from LPG based upon molecular recognition
   technology. Structure, Adsorptive Separations, and Characterization of
   Surfactant/Clay Complexes C.D. Muzny, T.J. Bruno, and H.J.M. Hanley
   (838) Details provided in the Environmental Measurements section.
   Atmospheric Lifetimes, OH Kinetics, and UV Spectra of
   Bromine-Substituted Fluoroalkenes V.L. Orkin, R.E. Huie, M.J. Kurylo
   (838), and F. Louis (Guest Researcher) Although a number of
   bromine-free substances have been proposed and tested as fire
   suppressants, bromine-containing compounds continue to attract interest
   as very efficient, chemically-active flame suppressants. Both
   bromofluoroalkenes and hydrobromofluoroethers are under consideration
   as Br-containing halon replacements. Fully substituted The presence of
   either a carbon-carbon double bond or a chlorofluorobromocarbons are
   carbon-hydrogen moiety is expected to render these excellent chemicals
   for use in substances reactive towards the tropospheric hydroxyl
   various industrial applications radicals, resulting in a short
   atmospheric lifetime. In order to and for fire suppression; quantify
   these atmospherically important properties, the however, their
   production is being phased out due to the reactivity of
   bromofluoroethers and brominated fluoroalkenes considerable danger they
   pose to hydroxyl radicals (OH) was investigated. Rate constants to the
   Earth's ozone layer. were measured over the temperature range 250 K to
   370 K using a flash photolysis-resonance fluorescence technique. In
   addition, ultraviolet absorption spectra of all these compounds between
   160 nm and 280 nm and infrared absorption spectra between 400 cm-1 and
   2000 cm-1 were measured, and the atmospheric lifetimes of the compounds
   calculated. Preliminary results of ab initio calculations were obtained
   for reactions of fluoroalkanes and fluoroethers with OH. Present
   experimental activity is focused on OH reactions with other classes of
   industrial compounds. The results are being utilized together with the
   ab initio calculations in order to create a screening tool for the
   reactivity estimations of industrial compounds. 83 Mechanisms for the
   Formation of Polychlorinated Organics During Combustion W. Tsang (838)
   and V. Babushok (Guest Researcher) -6 The formation of polychlorinated
   aromatics in Cl Cl 2 an incineration system represents an interesting
   mechanistic problem since the overall chlorine concentration as well as
   the initial chlorine content of any particular organic compound is -7
   low. Thus, the concentration of chlorine in C 6 H 4 Cl 2 particular
   molecules is a reflection of the C C 3 H 3 6 H 2 Cl 4 C 6 special
   mechanism that must be operative. H 3 Cl 3 C 6 H 6 Such effects have
   particular implications on the -8 C 6 HCl 5 formation of dioxins or
   dibenzofurans. The failure to find a reasonable gas phase C C 6 H 5 Cl
   6 Cl 6 mechanism has led to the general assumption C 3 H 2 Cl that
   these compounds must be formed by C 3 Cl 3 surface mediated processes.
   The incineration -9 0.001 environment was simulated on the basis of
   0.01 0.1 1 Chlorination products from the addition of time, s chemical
   kinetic modeling using published mixture from opposed propane air
   results pertaining to the combustion of diffusion flame at the maximum
   propargyl chlorinated hydrocarbons with the addition of concentration
   (§ 1ppm) into quenched reactions involving propargyl-type radicals.
   position of combustion products of Particular emphasis was placed on
   the mixing ethylene/dichloroethylene (5% enriched in and quenching of
   rich and lean mixtures. This oxygen [Cl]/[C] = 0.005 at 1000 K) model
   is a more faithful reflection of actual incineration operation than
   that of premixed fuel-air combustion. Initial results confirmed that it
   is impossible to obtain any degree of chlorine enrichment with a
   premixed sample, and in the absence of propargyl, enrichment could not
   be obtained even with mixing and quenching. The simulations showed that
   the temporal behavior of a number of species formed varies as a result
   of adding a very small amount of propargyl radicals into a quenched
   mixture of products from propane combustion with small amounts of
   typical chlorinated aromatic molecules. Distribution of chlorinated
   benzenes peaks at the two-to-four chlorine level. Combinations of these
   compounds result in the chlorines in dioxin or dibenzofurans peaking at
   the four chlorine level, in surprisingly good agreement with what is
   usually observed. These results demonstrate that even in the presence
   of trace chlorine, there is a very rich chemistry in the exhaust duct
   of incinerators. Furthermore, it is clear that for truly meaningful
   modeling of combustion systems, both fluid dynamics and chemical
   considerations must be combined. Measurement Technology for Benchmark
   Spray Combustion Data C. Presser (836), S.R. Charagundla, J.D. Widmann
   (864), S.D. Leigh (898), A.K. Gupta (Univ. Maryland), M.G. Giridharan
   (CFD Res. Corp.), and G. Papadopoulos (Dantec) Details provided in the
   Process Metrology section. Improved Methodologies for the Proper
   Treatment of Tunneling in Computational Kinetics C.A. Gonzalez , T.C.
   Allison, and F. Louis (838) Ever since the realization by Hund 63 years
   ago that tunneling This new methodology has might be important in the
   kinetics of chemical reactions, the already allowed scientists chemical
   literature has been "flooded" with fundamental work to properly compute
   the focusing on theoretical predictions as well as experimental
   kinetics of a series of confirmation of the role tunneling plays in
   chemistry. Tunneling is reactions relevant in the the result of quantum
   effects that tend to couple the reaction path area of atmospheric
   coordinate to the remaining degrees of freedom of the reacting
   chemistry. system due to curvature along the reaction path. The
   methodology developed in this project was tested on a series of H-atom
   abstraction reactions. The results show a significant improvement over
   the conventional 84 approach currently adopted by researchers, even in
   the case when simple tunneling models are used. In addition, research
   groups in industry and academia have recognized the potential impact of
   such a method in computational kinetics and have requested tools
   containing this method. We are extending the theory in order to devise
   robust diagnostic tools that will help scientists choose the most
   appropriate one-dimensional tunneling correction method in an automated
   fashion. Development of Efficient Tools for Computational Kinetics C.A.
   Gonzalez, F. Louis, T.C. Allison, R.E. Huie, and M.J. Kurylo (838)
   Application of quantum chemistry calculations in the area of Despite
   progress in computational kinetics will have a significant impact if
   the computational chemistry, the state-of-the-art methodologies are
   made widely available to area of computational kinetics the scientific
   community. Accordingly, the generation of still remains more of an art
   than computational tools that will allow scientists to perform a
   science, and therefore is used reliable studies of the kinetics
   governing a large variety of mostly by experts in the field. chemical
   reactions is critical. In this project, a series of The work by CSTL in
   this area will help make computational modules that compute rate
   constants as a function of the kinetics more of a science than
   temperature have been implemented into generic software. an art and
   thus open the field to Given its general acceptance, the Canonical
   Transition more researchers. State Theory (CTST) has been chosen as the
   standard method to compute rate constants. Tunneling corrections are
   calculated using the one-dimensional Wigner, symmetrical Eckart, or
   asymmetrical Eckart approaches. Ability to treat normal modes as
   hindered rotors was implemented. Additionally, properties such as
   vibrational frequencies, heats of reaction, entropies, and partition
   functions are also computed. The program was written in standard
   FORTRAN 77, and has the capability of reading output files from one of
   the most popular quantum chemistry programs. The computational kinetics
   tools utilized in this project have been applied to study the kinetics
   and reactivity of hydroxyl radicals towards a series of halogenated
   organic compounds, part of an ongoing project developing environmental
   impact "screening tools" for these compounds. Theoretical studies on
   more than twenty molecules have been performed using the program.
   Currently, variational transition state theory is being applied to
   reactions characterized by low barriers and for which CTST gives poor
   results. The methodologies used for tunneling correction calculations
   are being improved, and efficient algorithms are under development to
   enable rapid characterization of reactant rotational conformers that
   may contribute to the kinetics of the reaction. Additional calculations
   are being performed for halocarbons and ethers with one and two
   carbons. Fundamentals of van der Waals Interactions in Aromatic
   Clusters C.A. Gonzalez (838) Aromatic-aromatic interactions play
   important roles in many The results obtained in chemical and biological
   systems, including base-base interactions this research indicate that
   of the double helix of DNA, the function of photosynthetic reaction the
   combination of centers, the packing of aromatic crystals, the formation
   of molecular dynamics aggregates, and the conformational preferences of
   polyaromatic simulations followed by macrocycles and chain molecules.
   Proper description of the full geometry optimizations seem to
   interactions between monomers forming clusters of aromatic provide a
   reliable tool for molecules is critical for the fundamental
   understanding of these the study of vdW aromatic phenomena. The
   molecular systems ideally suited for a detailed clusters. study of the
   intermolecular potentials are van der Waals (vdW) dimers and higher
   clusters of aromatic hydrocarbons that are experimentally generated by
   free jet expansion techniques. Since these species form as a direct
   consequence of intermolecular interactions, the geometrical structures
   of the vdW molecules not only reveal the nature of the forces between
   the molecules but also provide an understanding of the cluster's other
   properties, including dynamics. Although significant efforts have been
   85 dedicated to experimental characterization of these clusters, the
   results are usually inconclusive. Highly correlated ab initio
   electronic structure methodologies could be a valuable tool to
   complement the experimental efforts. However, given the large size of
   these systems and the fact that the number of possible structures
   dramatically increases with the size of the cluster, reliable
   theoretical calculations have been limited to small clusters of benzene
   (dimer and trimer). It was therefore necessary to assess the validity
   of these methodologies in the case of larger clusters of different
   aromatic molecules and possibly determine if alternative methodologies
   that incur lower computational expenses can be applied to larger
   systems. We are currently extending the study to assess the basis set
   dependence of the theoretical treatment and, at the same time, to find
   more efficient alternatives to the methodologies so far used.
   Thermodynamic Interpretation of Gas-Phase Ion Chemistry K.K. Irikura
   (838) There is a large amount of thermochemical data on gas-phase
   reactions between ions and neutral CSTL researchers have recommended
   corrected procedures for extracting molecules. Neutral thermochemistry
   is often quantitative information from ion-molecule derived from
   thermodynamic cycles of such reactions. This type of measurement is
   experiments. The usual interpretation of the practiced internationally
   by dozens of experiments is that if the reaction is observed to
   research groups in academia and occur, it is presumed to be exothermic
   ( rH° 0). government. The resulting data are an An alternative
   interpretation assumes exoergicity important part of compilations, such
   as the ( NIST Chemistry WebBook, that are used rG° 0). Often, either
   interpretation is assumed without a clear reason for choosing one by
   scientists and engineers throughout the over the other, though the two
   interpretations can chemical sciences. lead to different results. The
   discrepancies can be large (tens of kJ mol-1) for reactions with large
   entropy changes ( rS° >> 0). This confusion is a serious problem in
   extracting thermochemical data from ion-molecule reactions.
   Practitioners must update their methods, and data compilations must be
   examined for major errors. Recent controversy over the adiabatic
   ionization energy of the CF3 radical arose with two nearly concurrent
   reviews recommending values differing by more than the uncertainties in
   any of the many experiments cited. Upon analysis, the conflict could be
   traced to the interpretation of ion- molecule reactions that have large
   entropy changes (two reactants leading to three products). The
   disagreement was reconciled using the exoergicity interpretation ( rG°
   0) with the final result in excellent agreement with very high-level ab
   initio calculations from the two different research groups. We
   concluded that the exoergicity interpretation is more accurate and
   should be used by all investigators, thus resolving the decades-old
   confusion. Monte Carlo Methods for Optimizing the Quantitative Analysis
   of Thin Layers, Microparticles and Irregular Surfaces J.T. Armstrong
   (837) One of the most promising approaches is the use of Electron
   microbeam analysis is Monte Carlo simulations to model the electron and
   X-ray very well suited for qualitative path lengths in complex samples.
   However, the various characterization of layered models and physical
   parameters commonly used in materials, particles and rough these
   calculations give significantly different analytical surfaces; however
   accurate results. The Monte Carlo algorithms of Joy and quantitative
   analysis of specimens Armstrong were modified to develop a versatile
   with irregular boundaries has simulation program that calculates X-ray
   emission from remained elusive. Many industrial applications require
   accurate thin films, particles and rough surfaces of given boundary
   analyses of such samples and a conditions. The program allows
   defocusing, or rastering, variety of methods have been of the electron
   beam to any given size, and proposed. bombardment of any portion of the
   particle or rough surface. It calculates the electron trajectories at a
   rate of approximately one million electrons per minute and is
   modularized to allow for easy substitution 86 for the various physical
   expressions that make up the model. The program was used to determine
   analytical, geometrical and compositional conditions that are
   particularly sensitive to the choice of physical parameters used in the
   Monte Carlo models and the results were in good agreement with
   previously developed geometric corrections and experimental analyses,
   particularly in showing the magnitude of electron sidescattering and
   its effect on X-ray production. This scattering is sensitive to the
   parameters of the program, resulting in large variations in the
   relative X-ray intensities with closeness to a sample side, with beam
   to sample angle, and with beam voltage. The Monte Carlo calculations
   showed variation in emitted X-ray intensities of particles of AlNi by
   greater than a factor of 100 with model-dependent variations of over a
   factor of two. The calculations are being used to identify the best
   measurement experiments and sample compositions to test the physical
   parameters. Appropriate analyses will then be made on such specimens to
   determine the best equations to use for quantitative analysis.
   Application of Process Models and Controllers to Semiconductor
   Processing R.W. Davis, J.E. Maslar, E.F. Moore (836), D.R. Burgess, Jr.
   (838), R.L. Axelbaum (Washington University), and S.H. Ehrman
   (University of Maryland) Details provided in the Microelectronics
   section. Measurements and Models for Plasma Processing of
   Semiconductors M. Sobolewski, K. Steffens (836), J. Olthoff, Y. Wang,
   L. Christophorou, A. Goyette (811), and E. Benck (842) Details provided
   in the Microelectronics section. The Protein Data Bank (PDB) T.N. Bhat,
   H. Cheng, D. Hancock, V. Ravichandran, N. Thanki, M. Tung, G.L.
   Gilliland (831), and P. Fagan (TS) The PDB is the international
   depository for three-dimensional biological macromolecular structural
   data, including X-ray, NMR, cryoelectron microscopy and theoretical
   modeling data. Users include a diverse group of researchers in biology,
   chemistry, as P Prrootteeiinn D Daattaa B Baannkk well as scientists,
   educators, and students at all levels. A key component of creating the
   public archive of information CSTL is meeting the needs of the is the
   efficient capture and curation of the data, termed emerging and rapidly
   growing data processing. Data processing consists of data biotechnology
   industry through deposition, annotation, validation and uniformity.
   database development, Historical inconsistencies in the way data are
   reported measurement development, data within PDB files may lead to
   inaccurate and incomplete acquisition for modeling, and query results.
   The introduction of the advanced modeling and tool development for
   querying capabilities of the PDB makes it critical to taking advantage
   of the enormous accelerate the data uniformity process for these data.
   amounts of biological data being Tables of consistent data are being
   developed to obtained. improve query results. Numerous data fields have
   been re-examined across the archive, made uniform and added to the
   database resources to make search results reliable. Cross links were
   created for files of related NMR determined structures, providing
   minimized average structures linked with their ensemble structures on
   the query results pages. Paper files of the Master Archive were
   bar-coded and transferred to an automated filing system, and a scanning
   station is used to The PDB processes and incorporates about 50 convert
   the paper archive to an electronic archive. Missing data structures per
   week into the are being sought from old depositor tapes that database.
   Usage is currently were read and transferred to CD-ROM. The about
   90,000 web hits per day Master Archive also produces quarterly and
   70,000 PDB files snapshots of the PDB resource as a set of CD-
   downloaded per day. ROMs that are distributed to the user community.
   Work to archive snap shots of the PDB Website 87 and reproduce them for
   historical reference has begun. The completion of the human genome has
   made the role of structure in nucleic acid function of particular
   interest. The PDB users show an increasing demand for more and better
   data and access. It is estimated that the PDB, which currently contains
   more than 13,600 structures, could triple or quadruple in size over the
   next 5 years. The approach of using modern data management practices
   should permit scaling to accommodate a large data influx. Lispix Image
   Processing System Available for PC and Macintosh D.S. Bright (837) Over
   the last decade, MacLispix, a public domain image processing system for
   the Macintosh, has been applied to a variety of image processing
   problems. Due to interest from the PC community as well as the
   migration of the NIST Microanalysis Group to Windows machines, the
   software was ported to Windows, renamed 'Lispix', and distributed for
   both platforms, along with example images, source and documentation.
   MacLispix was written in an enhancement of the Common Lisp programming
   language, providing graphical user interface (GUI) functions using
   special calls to the Macintosh Tool Box. Common Lisp (CL) for other
   operating systems do not have such calls, but instead have special
   routines for graphics and for mouse input. Our approach was to split
   the MacLispix code into a larger CL portion, and two smaller libraries.
   The development of image processing tools for our research is done
   entirely in the CL portion, so that development can be done using
   either the Mac or PC platform, and the tool will work similarly on both
   platforms without any additional or special code. The libraries, on the
   other hand, have the special graphics and GUI calls for their
   respective systems, but they look alike as far as the CL portion is
   concerned. Sufficient MacLispix tools have been ported to Windows to
   make the system useful both as a research tool for the Microanalysis
   Group and as an image processing system for outside users. We now are
   planning to port Lispix to Linux, and add more image processing tools
   to all platforms. A Prototype Database for Evolutionary Analysis of
   Gene Families A. Stoltzfus (831), W.-G. Qiu (CARB/UMBI) The integration
   of evolutionary methods of character analysis into bioinformatics is a
   logical development that has yet to take place. Strategies for genome
   annotation and functional inference, a kind of comparative evolutionary
   inference (rather than an a priori prediction), are usually based on
   ranking of sequence alignments (BLAST scores), rather than on
   phylogenetic analysis. Phylogenetic methods that take into account the
   hierarchical structure of variance in biological data are superior for
   recovering functional relationships and identifying conserved
   functional features. However, the application of such methods to the
   analysis of genes on a broad scale faces several obstacles, including
   technical obstacles, like heterogenous tools and file formats, and
   conceptual difficulties, such as i) developing a system for querying
   relationships among gene families with different trees, and ii)
   accessing the uncertainty of phylogenetic trees and reconstructed
   ancestral character states. As a test case for automated analysis of
   character evolution in gene families, issues concerning the evolution
   of introns in eukaryotic genes were addressed using a prototype
   database system. Introns were designated as presence/absence
   characters, and the focus for detecting patterns and testing
   hypotheses, relate to their loss and gain rather than changes in intron
   length or sequence. The hypothesis that introns are gained at a
   non-random "target site" is of special interest. Data for three gene
   families, triosephosphate isomerase, Cu,Zn superoxide dismutase, and Mn
   superoxide dismutase, were collected from GenBank. The resulting gene
   family data sets were augmented with reconstructed histories of the
   loss and gain of introns. Database tools were developed to query the
   phylogenetic reconstructions to identify segments of genes
   corresponding to sites at which an intron was gained in a sister taxon,
   representing an estimate of the intron "target site". Results confirmed
   that introns are gained at a target site which is non-random at
   positions upstream and downstream of the intron, with the consensus
   sequence being AAG^GT. Current work includes (1) continued development
   of software tools for automated phylogenetic analysis, (2) designing
   more rigorous statistical tests and (3) expanding the database to
   include more gene families 88 Biospectroscopy A.K. Gaigalas, V. Reipa,
   V.L. Vilker (831), G. Valincius (Vilnius State University, Vilnius,
   Lithuania), L.L. Wang (William and Mary College), A. Schwartz (Center
   for Quantitative Cytometry) Details provided in the Bio-Molecules and
   Materials section. Biothermodynamics R.N. Goldberg, Y.B.Tewari (831),
   N. Kishore (Indian Institute of Technology, Bombay) Reaction conditions
   such as temperature, pH, ionic strength, and Knowledge of chemical
   co-factor concentrations can substantially affect the equilibrium of
   equilibrium is essential many biochemical reactions. Chromatography,
   microcalorimetry, for predicting the thermodynamic modeling, and
   literature data are used to measure feasibility of chemical
   thermodynamic quantities and assemble databases for enzyme- reactions,
   particularly catalyzed reactions. The microcalorimetric capability has
   been when optimizing industrial processes. particularly important for
   the extrapolation of data to higher temperatures. This effort has also
   resulted in the development of estimation schemes based upon limited
   and carefully chosen sets of data. Recent research focused on reactions
   in the chorismate metabolic pathway that has been a focal point of
   interest because of its potential industrial importance. CSTL
   researchers have now characterized the thermodynamics of a major
   portion of this pathway by studying the reactions catalyzed by
   tryptophan synthase, prephenate dehydrogenase, prephenate dehydratase,
   chorismate lyase, chorismate mutase, glutaminase, and tyrosine
   aminotransferase. This past year, microcalorimetry and high performance
   liquid chromatography were used to conduct a thermodynamic
   investigation of reactions catalyzed by DAHP synthase, the first enzyme
   in the metabolic pathway leading to chorismate. Currently, the
   thermochemistry of adenosine(s) is being studied by combustion
   calorimetry, adiabatic calorimetry over the temperature range 11 K to
   328 K, and HPLC for determining the saturation molality of adenosine in
   water. These measurements will be useful for calculating standard molar
   formation properties for the adenosine 5'-monophosphate (AMP),
   adenosine 5'-diphosphate (ADP), and adenosine 5'-triphosphate (ATP)
   series of aqueous species. Energetics of Genetics: Activation of
   Transcription F.P. Schwarz (831), Y. Shi, S. Wang (UMBI), S. Krueger
   (MSCL), S. Gregurick (UMBC), and B. Wladkowski (Western Maryland
   College) Details provided in the Bio-Molecules and Materials section.
   Collation of Experimental Data on Amino Acid Exchangeability A.
   Stoltzfus (831) and L.Y. Yampolsky (CARB/UMBI) Bioinformatics methods
   that rely on a matrix of amino acid similarity scores typically use
   Dayhoff- type matrices based on evolutionary divergence. From the
   perspective of understanding the structure and evolution of proteins,
   such matrices are problematic in that they are influenced in an unknown
   way by mutation rates, so that one does not know, for instance, whether
   the Cys-to-Met value is low for reasons of protein structure, or for
   reasons of mutation, since converting a Cys codon (TGY) to a Met codon
   (ATG) requires mutational change at all three nucleotide positions. To
   develop a measure of amino acid exchangeability that is uninfluenced by
   mutation requires a different approach. Results of experimental amino
   acid exchanges were collated from published studies. The resulting
   exchangeability matrix was evaluated by testing for expected a priori
   correlations, such as a positive correlation with widely used amino
   acid scoring matrices. Data on over 8000 individual amino acid
   exchanges were collated. The resulting exchangeability values
   correlated significantly with chemical indices of amino acid
   similarity, and with divergence-based matrices used for database
   searching. In spite of a variety of sources of heterogeneity in
   experimental conditions, the exchangeability matrix contains a
   significant and potentially useful signal. Work is underway to
   incorporate the exchangeability matrix into a general codon-based 89
   model of protein sequence evolution that includes separate parameters
   for mutational effects and protein effects. This model may then serve
   as the basis for generating tunable, task-specific amino acid score
   matrices, whose suitability will be evaluated for alignment tasks
   (database searching, fold-recognition), functional inference, and
   phylogenetic reconstruction. Individual-Based Models of the Effect of
   Mutation Bias on Evolution A. Stoltzfus (831) and L.Y. Yampolsky
   (CARB/UMBI) The general objective is to develop the theoretical basis
   for understanding the role of mutation in evolution. More specifically,
   this work aims to provide theoretical models for the influence of
   biases in mutation on the direction of evolutionary change. According
   to contemporary evolutionary theory, mutation biases influence the
   direction of evolution only in the special case of neutral evolution.
   Nevertheless, modern sequence divergence data suggest that mutation
   biases have figured importantly in the evolution of genes and proteins.
   Rather than implicating neutral evolution, such results may instead
   suggest the need to re-evaluate the manner in which mutation is treated
   in evolutionary models. In classical evolutionary theory, the existence
   of allelic variation is taken for granted, so that the introduction of
   novel alleles by individual mutation events is seen to play no
   appreciable role. The key to understanding the role of mutation bias in
   evolution may lie in exploring this novelty-introducing role of
   mutation. Our theoretical study of this role is based on a simple
   2-locus, 2-allele case of the classic Bateson-Dobzhansky-Muller fitness
   scheme. An initial population of ab individuals may evolve toward one
   of two genotypes of higher fitness, Ab or aB, each of which is more fit
   than AB. Since the initial population is composed solely of ab
   individuals, mutation (rather than an assumption of initial variation)
   is required. To explore the influence of mutation bias, mutation to aB
   occurs at a higher rate than mutation to Ab. The stronger the mutation
   bias, the more likely is evolution to proceed in the direction favored
   by mutation, an effect that does not rely on a high overall mutation
   rate (u). When mutations are rare (uN << 1), the biasing effect of
   mutation is approximately proportional to the mutation bias and to the
   bias in selection coefficients, and is not strongly affected by the
   magnitude of mutation or of selection coefficients. As anticipated,
   this effect requires that mutation act as a novelty-introducing
   process: mutation bias is ineffectual if variant alleles are simply
   assumed to exist initially, even at low frequencies. Future plans
   include further theoretical work with the goal of exploring many-locus
   (not just 2-locus) models, and empirical studies to gauge the extent to
   which mutation biases are reflected in evolutionary divergence of genes
   and proteins. Predicted versus Experimental PNA/DNA and DNA/DNA Duplex
   Stabilities F.P. Schwarz, M. Chakrabarti (831), and S. Krueger (MSEL)
   Peptide nucleic acids (PNAs) are analogues of DNA, where the four
   nucleosides, A, G, C, and T are linked by a N-(2-aminoethyl) glycine
   backbone instead of the phosphate backbone in DNA. PNAs are able to
   form Watson-Crick pairs with complementary DNA base sequences that are
   more stable than their analogue DNA/DNA duplexes. Unlike DNAs, PNAs are
   electrostatically neutral and biologically inert, which have lead to
   their use in many areas of the health sciences, including single
   nucleotide polymorphism genotyping, PCR clamping, and inhibition of
   enzymatic activity in cells. All of these applications are critically
   dependent on Go for binding of PNA, as well as DNA, to their
   complementary DNA sequences over a wide range of temperatures and thus,
   would be facilitated by a model predicting Go from the sequence of the
   PNA. Predictive models have been developed for predicting the
   stabilities of DNA duplexes but have only been validated from 310-350
   K. The thermodynamic parameters were determined from isothermal
   titration calorimetry (ITC) measurements on the binding of PNA and of
   DNA to their complementary DNA sequences to form, respectively, the
   PNA/DNA hybrid and DNA duplexes at ambient temperatures, and from UV
   absorption melting and differential scanning calorimetry measurements
   on the dissociation of the duplexes at high temperatures. Contributions
   to the thermodynamic parameters from 90 conformational changes in the
   single PNA and DNA strands were determined from small angle neutron
   scattering (SANS) measurements on the PNA and DNA strands over this
   temperature range. The high temperature thermodynamic parameters were
   extrapolated to ambient temperatures and compared to their values
   determined from ITC measurements. Implications of these studies are
   that the conformational contributions may be predictable from the
   strand sequence. The Go values for the DNA duplexes were in good
   agreement with predicted values from the literature. A comparison of
   the 8 and 10 base pair duplexes show significant contributions to the
   Go values from changes in the single 10 base pair strand conformations.
   Any predictive model applicable over a wide temperature range must take
   this into account. The Go values for the shorter 8 base pair DNA
   duplexes, however, are predictable from the nearest- neighbor
   Watson-Crick model using the literature assignments. Thermodynamic
   binding parameters are being determined for longer 12 base pair PNA/DNA
   and DNA duplexes to determine if single strand conformational changes
   also contribute to these binding parameters. These values will also be
   used along with the 10 and 8 base pair PNA/DNA duplex Go values to
   determine the 16 assignments needed to predict the hybrid duplex
   stabilities. In addition, the dependence of the single strand
   conformational contributions on sequence will also be determined and
   used to refine the nearest-neighbor Watson-Crick model to correctly
   predict Go values for all the duplexes over a wide range of
   temperatures. A Computer Program to Determine the Effects of Single
   Nucleotide Polymorphisms (SNPs) and Mutations in Human Mitochondrial
   DNA B.C. Levin and M.S. Lee (831) Details provided in the DNA
   Technologies section. 91 92
